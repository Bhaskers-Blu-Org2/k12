{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "# Cognitive Hackathon: Week 1 - Teacher's Guide\n## Day 1\n\n## Overview\n\nThe first day is about exploring what is possible in the world of cognitive computing. The years ahead of us will see astounding growth and change in this area, and the related changes to our culture and commerce are expected to supercede even the Internet. It will be an exciting time ahead and the examples and concepts in this course provide a hint of what is to come. \n\n## Objectives\n\nToday, demonstrate examples of cognitive computing while introducing the foundational concepts, including machine learning, models, and artificial intelligence. Explore the Azure Cognitive API in all of its facets, with special focus on Computer Vision and Text Analytics.\n\nHere are the demos to begin with:\n\n## Teacher Demos: Cognitive Computing \n\nDemonstrate these first examples use cognitive Computer Vision capabilities that allow the machine to look at an image and make certain determinations. \n\n## Teacher Demo: How Old (10 mins)\n\nIn this first one, it's to guess peoples' age. Now this can be a fun party trick, like the person at the fair who guesses your age, but this technology could also be used to better estimate demographics of people visiting a particular landmark without needing to collect any other personal information, or analyze the covers of magazines to see what age group is more frequently on the cover of which magazine.\n\n    https://www.how-old.net/\n\n### Teacher Leads Discussion (10 mins)\nDiscuss what's going on in the How Old cognitive app, for example: \n- Facial Recognition: The app must first find the person, so it needs to know what a face looks like, then it draws a rectangle around the face. \n- Multiple People: Sometimes there's more than one face in the frame (show example) so the app must identify two or more faces. \n- Facial Features: The app analyzes each face, looking for traits that help it guess the age. Which facial features might the app be using to determine age? (It's amazing enough that a computer can tell that it's looking at a person, but even moreso that it knows if they're young or old!)\n\n##  Teacher Demo: What Dog (10 mins)\n\nHow about creatures other than humans? Like dogs, for instance. It might be useful for an animal shelter to be able to determine the breed of a dog that was recently brought in to more accurately represent it to folks who are looking to adopt an animal.  What-dog.net does just that:\n\n    https://www.what-dog.net/\n\n### Teacher Leads Discussion: Visual Cognitive Computing (10 mins)\n Explore aspects of visual cognitive computing by how-old.net and what-dog.net apps, their similarities and differences:\n* How do you think the what-dog.net knows the species of the dogs in those pictures with such accuracy?\n* How might how-old.net be able to guess at ages?\n* Facial Recognition: The app must know something about the anatomy of what its looking at, likely finding the dog's face.\n* Facial Features: What are the different facial features on a dog that determine breed that you wouldn't use on a human? Things like the shape of the eyes, and the length of the ears and snout. \n* Color: Using pattern recognition to navigate anatomy, the app is  most certainly looking at the color of the dog's fur, and may even identify a tail \n\n## Teacher Presents: Cognitive Computing Concepts (10 mins)\n\nCognitive systems use something called machine learning, which allows apps to learn almost like children do, by observing lots and lots of examples. Thousands of dogs are shown to this app, with the species of each dog named to the app, until it compiles an understanding of the traits of each species of dog.  This understanding is stored in a construct called a model.  Cognitive computing is the creation of a model using machine learning then the utilization of that model by the cognitive algorithms to make determinations and recommendations.\n\nHere are the main concepts:\n\n* Cognitive Computing - use of models created by machine learning to identify and qualify images, speech, text, etc. \n* Machine Learning - the creation of models through the analysis of large amounts of data (often called \"Big Data\")\n* Model - data representation of the computer's understanding of a data set using machine learning, used by cognitive computing APIs and apps to conduct analysis and make complex determinations\n\nIn this course we'll be using a cognitive API which contains ready-made machine learning models that your applications can consume using REST APIs. Think of it as a shortcut. There's no need to gather the training data, create a learning algorithm, or train the model. Configuring machine learning systems to analyze large swathes of data to build models could take an entire semester. We will focus on APIs with prepared functionality to give you more time to explore the possibilities of cognitive computing.\n\nSo what are these cognitive APIs?\n\n## Teacher Presents: Cognitive Computing APIs (10 mins)\n\nThere are quite a few features in the cognitive API we're working with:\n\n    https://azure.microsoft.com/en-us/services/cognitive-services/directory/\n\nYou can do an online demo these APIs using the \"Demo\" link next to the APIs.\n\nSee the tabs at the top of the window for our Azure Cognitive Services:\n\n* Vision\n* Speech\n* Language\n* Anomaly Detection\n* Search\n\nEach of these tabs contains a group of cognitive APIs:\n\n### Vision\nExtract information from images to categorize and process visual data. Perform machine-assisted moderation of images to help curate your services.\n* Computer Vision\n* Video Indexer\n* Face \n* Custom Vision\n* Content Moderator\n\n### Speech\nTranslate between speech, text, and other languages as well as identify speakers.\n* Speech to Text\n* Text to Speech\n* Speaker Recognition\n* Speech Translation\n\n### Language\nBuild apps that comprehend text and its grammar, meaning, and emotion.\n* Text Analytics\n* Bing Spell Check\n* Content Moderator (again)\n* Translator Text\n* QnA Maker\n* Language Understanding\n\n### Anomaly Detection\nIdentify problems in real time.\n* Anomaly Detector\n\n### Search\nAdd search capability for finding and identifying web pages, images, videos, and news.\n* Bing Web Search\n* Custom Search\n* Video Search\n* Image Search\n* Local Business Search\n* Visual Search\n* Entity Search\n* News Search\n* Autosuggest\n\n## Summary\nThis first workshop covered these topics:\n* Cognitive computing demonstrations\n* Concepts: cognitive computing, model, machine learning\n* Breadth of many types of cognitive computing APIs\n\n[<< Week 1 Summary](https://sp19azureteachersguide-sguthals.notebooks.azure.com/j/notebooks/Week%201/README.ipynb)          [Day 2 >>](https://sp19azureteachersguide-sguthals.notebooks.azure.com/j/notebooks/Week%201/Day2.ipynb]"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": ""
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}